# app.py

import streamlit as st
import pandas as pd
from typing import Optional

# LangChain + Conexi√≥n
from langchain_openai import ChatOpenAI
from langchain_community.utilities import SQLDatabase

# Importa el constructor del grafo y la herramienta de audio
from graph_builder import create_graph
from tools import text_to_audio_elevenlabs

# Componente de micr√≥fono
from streamlit_mic_recorder import mic_recorder

# --- C√ìDIGO DE DEPURACI√ìN TEMPORAL (PUEDES BORRARLO DESPU√âS) ---
st.subheader("üïµÔ∏è Verificaci√≥n de Secretos")
try:
    st.write("1. LANGCHAIN_TRACING_V2 es 'true':", st.secrets.get("LANGCHAIN_TRACING_V2") == "true")
    st.write("2. LANGCHAIN_API_KEY existe y no est√° vac√≠a:", "LANGCHAIN_API_KEY" in st.secrets and bool(st.secrets.get("LANGCHAIN_API_KEY")))
    st.write("3. LANGCHAIN_PROJECT:", st.secrets.get("LANGCHAIN_PROJECT", "NO ENCONTRADO"))
    st.write("4. ELEVENLABS_API_KEY existe:", "elevenlabs_api_key" in st.secrets and bool(st.secrets.get("elevenlabs_api_key")))
except Exception as e:
    st.error(f"Ocurri√≥ un error al intentar leer los secretos: {e}")
st.divider()
# --- FIN DEL C√ìDIGO DE DEPURACI√ìN ---


# ============================================
# 0) Configuraci√≥n de la P√°gina y T√≠tulo
# ============================================
st.set_page_config(page_title="IANA con LangGraph", page_icon="logo_autollantas.png", layout="wide")

col1, col2 = st.columns([1, 4])
with col1:
    st.image("logo_autollantas.png", width=120)
with col2:
    st.title("IANA: Tu Asistente IA para An√°lisis de Datos")
    st.markdown("Soy la red de agentes IA de **AutoLLantas**. Preg√∫ntame algo sobre tu negocio.")

# ============================================
# 1) Conexi√≥n a BD, LLMs y Grafo (REFACTORIZADO)
# ============================================

@st.cache_resource(show_spinner="üõ∞Ô∏è Conectando a la base de datos...")
def get_db_connection():
    """Crea y cachea la conexi√≥n a la base de datos."""
    creds = st.secrets["db_credentials"]
    uri = f"mysql+pymysql://{creds['user']}:{creds['password']}@{creds['host']}/{creds['database']}"
    engine_args = {"connect_args": {"ssl_disabled": True}}
    db = SQLDatabase.from_uri(uri, include_tables=["automundial"], engine_args=engine_args)
    
    # Prueba r√°pida de conexi√≥n
    try:
        db.run("SELECT 1")
    except Exception as e:
        st.error(f"Error al conectar a la base de datos: {e}")
        # Detiene la app si la BD falla, ya que es cr√≠tico
        st.stop() 
    return db

@st.cache_resource(show_spinner="ü§ù Inicializando los LLMs...")
def get_llms():
    """Crea y cachea los modelos de lenguaje."""
    try:
        api_key = st.secrets["openai_api_key"]
        model_name = "gpt-4o"
        llms = {
            "sql": ChatOpenAI(model=model_name, temperature=0.1, openai_api_key=api_key),
            "analista": ChatOpenAI(model=model_name, temperature=0.1, openai_api_key=api_key),
            "orq": ChatOpenAI(model=model_name, temperature=0.0, openai_api_key=api_key),
            "validador": ChatOpenAI(model=model_name, temperature=0.0, openai_api_key=api_key),
        }
        return llms
    except Exception as e:
        st.error(f"Error al inicializar los LLMs (revisa tu API key): {e}")
        st.stop()

@st.cache_resource(show_spinner="üï∏Ô∏è Construyendo la red de agentes...")
def get_graph():
    """
    Crea el grafo de LangGraph.
    Depende de get_db_connection() y get_llms().
    """
    # Llama a las otras funciones cacheadas.
    # Si ya existen, las devuelve instant√°neamente.
    # Si no, las crea (mostrando sus spinners).
    db = get_db_connection()
    llms = get_llms()
    
    graph_app = create_graph(llms, db)
    st.success("‚úÖ Red de agentes IANA compilada con LangGraph.")
    return graph_app

# --- Bloque principal de inicializaci√≥n ---
# Intentamos obtener el grafo. Esto, por dependencia,
# inicializar√° la BD y los LLMs en el orden correcto
# y solo la primera vez.
try:
    get_graph() 
    # Ya no necesitamos guardar esto en st.session_state
    # porque podemos llamar a get_graph() desde cualquier parte.
except Exception as e:
    # Si algo falla en la cadena de cach√© (BD, LLM, Grafo),
    # se mostrar√° el error espec√≠fico de la funci√≥n que fall√≥.
    st.error(f"‚ùå Error cr√≠tico durante la inicializaci√≥n.")
    # st.stop() es llamado dentro de las funciones si fallan.


# ============================================
# 2) Interfaz: Chat y Procesamiento de Preguntas
# ============================================
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": {"texto": "¬°Hola! Soy IANA. ¬øQu√© te gustar√≠a analizar hoy?"}}]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        content = message.get("content", {})
        if isinstance(content, dict):
            if content.get("texto"): st.markdown(content["texto"])
            if isinstance(content.get("df"), pd.DataFrame) and not content["df"].empty: st.dataframe(content["df"])
            if content.get("analisis"): st.markdown(content["analisis"])
        elif isinstance(content, str):
            st.markdown(content)

def procesar_pregunta(prompt: str):
    try:
        # Obtenemos el grafo desde la cach√©.
        # Esto es instant√°neo si ya fue creado.
        graph = get_graph() 
    except Exception as e:
        st.error(f"Error al obtener la red de agentes: {e}")
        return

    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("Pensando..."):
            initial_state = {
                "pregunta_usuario": prompt,
                "historial_chat": st.session_state.messages
            }
            # Usamos la variable local 'graph'
            final_state = graph.invoke(initial_state)

            response_content = {}
            response_text = None

            if final_state.get("error"):
                response_text = f"‚ùå Lo siento, ocurri√≥ un error: {final_state['error']}"
                response_content["texto"] = response_text
                st.error(response_text)
            else:
                if final_state.get("respuesta_final"):
                    response_text = final_state["respuesta_final"]
                    response_content["texto"] = response_text
                    st.markdown(response_text)
                
                if final_state.get("df") is not None and not final_state["df"].empty:
                    response_content["df"] = final_state["df"]
                    st.dataframe(response_content["df"])
                
                if final_state.get("clasificacion") == "analista" and final_state.get("analisis"):
                    response_content["analisis"] = final_state["analisis"]
                    if not response_text: # Si no hab√≠a ya una respuesta de texto, usamos el an√°lisis para el audio
                        response_text = final_state.get("analisis")

            st.session_state.messages.append({"role": "assistant", "content": response_content})

            # --- L√ìGICA DE AUDIO AUTOM√ÅTICO ---
            if response_text:
                with st.spinner("üéôÔ∏è Generando voz..."):
                    audio_data = text_to_audio_elevenlabs(response_text)
                
                if audio_data:
                    st.audio(audio_data, format='audio/mpeg', autoplay=True)


# --- Input del usuario: Micr√≥fono y Texto ---
st.markdown("### üé§ Habla con IANA o escribe tu pregunta")

# Contenedor para alinear los inputs
col1, col2 = st.columns([1, 4])

with col1:
    # Usamos mic_recorder, que devuelve los bytes del audio
    audio_bytes = mic_recorder(
        start_prompt="‚ñ∂Ô∏è Grabar",
        stop_prompt="‚èπÔ∏è Detener",
        key='mic'
    )

with col2:
    # El chat_input normal
    prompt_text = st.chat_input("... o escribe tu pregunta aqu√≠")

# Procesar la entrada de texto
if prompt_text:
    procesar_pregunta(prompt_text)

# Procesar la entrada de voz (si la hay)
if audio_bytes:
    # Convertir los bytes de audio a texto
    # (Aqu√≠ necesitar√≠as tu propia l√≥gica de Speech-to-Text, por ejemplo con la API de OpenAI)
    # Por ahora, simularemos la transcripci√≥n
    st.warning("Funcionalidad de voz a texto no implementada en este ejemplo. Procesando como si fuera un texto de prueba.")
    procesar_pregunta("Esta es una prueba de voz.")
